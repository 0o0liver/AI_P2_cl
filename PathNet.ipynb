{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PathNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qhDlkNIBpuY0",
        "6sjChmPcIe7b",
        "-BlDasoOZ-dr",
        "NnM9oAWHqJcT"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dchu1/AI_P2_cl/blob/master/PathNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhDlkNIBpuY0",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeD2BTRwpw0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch.utils.data as data_utils\n",
        "import math\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import gradcheck\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "from IPython.core.debugger import set_trace\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.nn import Module\n",
        "from __future__ import division\n",
        "\n",
        "n_tasks = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sjChmPcIe7b",
        "colab_type": "text"
      },
      "source": [
        "# Constructing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTOALc9Zusuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate_dataset(d, rotation):\n",
        "  result = torch.FloatTensor(d.size(0), 784)\n",
        "  tensor = transforms.ToTensor()\n",
        "\n",
        "  for i in range(d.size(0)):\n",
        "    img = Image.fromarray(d[i].numpy(), mode=\"L\")\n",
        "    result[i] = tensor(img.rotate(rotation)).view(784)\n",
        "  return result\n",
        "\n",
        "mnist_path = \"mnist.npz\"\n",
        "if not os.path.exists(os.path.join(\"/content\", mnist_path)):\n",
        "  subprocess.call(\"wget https://s3.amazonaws.com/img-datasets/mnist.npz\", shell=True)\n",
        "\n",
        "f = np.load(mnist_path)\n",
        "x_tr = torch.from_numpy(f[\"x_train\"])\n",
        "y_tr = torch.from_numpy(f[\"y_train\"]).long()\n",
        "x_te = torch.from_numpy(f[\"x_test\"])\n",
        "y_te = torch.from_numpy(f[\"y_test\"]).long()\n",
        "f.close()\n",
        "\n",
        "# Rotate Dataset\n",
        "tasks_tr = []\n",
        "tasks_te = []\n",
        "mnist_rot_path = \"mnist_rotations.pt\"\n",
        "if not os.path.exists(os.path.join(\"/content\", mnist_rot_path)):\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    for t in range(n_tasks):\n",
        "      min_rot = 1.0 * t / n_tasks * (180.0 - 0.0) + 0.0\n",
        "      max_rot = 1.0 * (t + 1) / n_tasks * (180.0 - 0.0) + 0.0\n",
        "      rot = random.random() * (max_rot - min_rot) + min_rot\n",
        "\n",
        "      tasks_tr.append([rot, rotate_dataset(x_tr, rot), y_tr])\n",
        "      tasks_te.append([rot, rotate_dataset(x_te, rot), y_te])\n",
        "\n",
        "    torch.save([tasks_tr, tasks_te], 'mnist_rotations.pt')\n",
        "else:\n",
        "    tasks_tr, tasks_te = torch.load('/content/mnist_rotations.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-BlDasoOZ-dr"
      },
      "source": [
        "# Genotype Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft0BF107TuLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Genotype():\n",
        "\n",
        "    def __init__(self, L, M, N):\n",
        "        self.genotype = np.random.randint(0, M, (L,N))\n",
        "        self.L = L\n",
        "        self.M = M\n",
        "        self.N = N\n",
        "\n",
        "    def apply_mutation(self, i, j):\n",
        "        gene = self.genotype[i][j] + random.randint(-2, 2)\n",
        "        if gene < 0:\n",
        "            gene += self.M\n",
        "        elif gene > self.M - 1:\n",
        "            gene -= self.M\n",
        "        self.genotype[i][j] = gene\n",
        "\n",
        "    def mutate(self):\n",
        "        for i in range(self.L):\n",
        "            for j in range(self.N):\n",
        "                if random.random() < 1.0 / (self.L * self.N):\n",
        "                    self.apply_mutation(i, j)\n",
        "\n",
        "    def return_genotype(self):\n",
        "        return self.genotype\n",
        "\n",
        "    def overwrite(self, genotype):\n",
        "        self.genotype = copy.deepcopy(genotype)\n",
        "\n",
        "\n",
        "class Genetic():\n",
        "\n",
        "    def __init__(self, L, M, N, pop): \n",
        "        \"\"\"\n",
        "        L: layers, M: units in each layer, N: number of active units, pop: number of gene\n",
        "        \"\"\"\n",
        "        self.genotypes = [Genotype(L, M, N) for _ in range(pop)]\n",
        "        self.pop = pop\n",
        "        self.control_fixed = random.sample(self.genotypes,1)[0]\n",
        "\n",
        "    def return_all_genotypes(self):\n",
        "        genotypes = [gene.return_genotype() for gene in self.genotypes]\n",
        "        return genotypes\n",
        "\n",
        "    def return_control(self):\n",
        "        return self.control_fixed\n",
        "\n",
        "    def return_control_genotype(self):\n",
        "        return self.control_fixed.return_genotype()\n",
        "\n",
        "    def sample(self):\n",
        "        return random.sample(self.genotypes, 2)\n",
        "\n",
        "    def overwrite(self, genotypes, fitnesses):\n",
        "        win = genotypes[fitnesses.index(max(fitnesses))]\n",
        "        lose = genotypes[fitnesses.index(min(fitnesses))]\n",
        "        genotype = win.return_genotype()\n",
        "        lose.overwrite(genotype)\n",
        "        lose.mutate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DIOkaIcca0N",
        "colab_type": "text"
      },
      "source": [
        "# PathNet Model 2 Layer Conv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIW5UOOtizUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, L, M, N, num_neurons, lr, use_cuda):\n",
        "        super(Net, self).__init__()\n",
        "        self.L = L\n",
        "        self.M = M\n",
        "        self.N = N\n",
        "        self.lr = lr\n",
        "        self.num_neurons = num_neurons\n",
        "        self.use_cuda = use_cuda\n",
        "        self.final_layers = []\n",
        "\n",
        "    def init(self, best_path, task):\n",
        "        nochange_modules = [[]] * self.L\n",
        "        if len(best_path) == 0:\n",
        "            nochange_modules = [[None] * self.M] * self.L\n",
        "        else:\n",
        "            for i in range(len(best_path)):\n",
        "                nochange_modules = np.concatenate((nochange_modules,best_path[i]), axis=1)\n",
        "        num_neurons = self.num_neurons\n",
        "        module_num = [self.M] * self.L\n",
        "  \n",
        "        # Construct our network. Don't touch modules that are frozen (nochange_modules)\n",
        "        self.fc1 = []\n",
        "        self.fc2 = []\n",
        "\n",
        "        for i in range(module_num[0]):\n",
        "            if not i in nochange_modules[0]:\n",
        "                \"\"\"All parameters should be declared as member variable, so I think this is the simplest way to do so\"\"\"\n",
        "                exec(\"self.m1\" + str(i) + \" = nn.Conv2d(1, 32, 3, 1)\")\n",
        "            exec(\"self.fc1.append(self.m1\" + str(i) + \")\")\n",
        "\n",
        "        for i in range(module_num[1]):\n",
        "            if not i in nochange_modules[1]:\n",
        "                exec(\"self.m2\" + str(i) + \" = nn.Conv2d(32, 64, 3, 1)\")\n",
        "            exec(\"self.fc2.append(self.m2\" + str(i) + \")\")\n",
        "\n",
        "        if task != None:\n",
        "            exec(\"self.final_layer\" + str(task) + \" = nn.Linear(9216, 10)\")\n",
        "            exec(\"self.final_layers.append(\" + \"self.final_layer\" + str(task) + \")\")\n",
        "\n",
        "        # Get our trainable params for the optimizer\n",
        "        trainable_params = []\n",
        "        params_set = [self.fc1, self.fc2]\n",
        "        for path, params in zip(nochange_modules, params_set):\n",
        "            for i, param in enumerate(params):\n",
        "                if  i in path:\n",
        "                    param.requires_grad = False\n",
        "                else:\n",
        "                    p = {'params': param.parameters()}\n",
        "                    trainable_params.append(p)\n",
        "                    \n",
        "        p = {'params': self.final_layers[-1].parameters()}\n",
        "        trainable_params.append(p)\n",
        "        self.optimizer = optim.SGD(trainable_params, lr=self.lr)\n",
        "        if self.use_cuda:\n",
        "            self.cuda()\n",
        "\n",
        "    def forward(self, x, path, last):\n",
        "        y = F.relu(self.fc1[path[0][0]](x))\n",
        "        for j in range(1,len(path[0])):\n",
        "            y += F.relu(self.fc1[path[0][j]](x))\n",
        "        x = y\n",
        "        y = F.relu(self.fc2[path[1][0]](x))\n",
        "        for j in range(1,len(path[0])):\n",
        "            y += F.relu(self.fc2[path[1][j]](x))\n",
        "        x = y\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.final_layers[last](x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "    def train_model(self, train_loader, path, num_batch):\n",
        "        self.train()\n",
        "        fitness = float(0)\n",
        "        train_len = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            if self.use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            data, target = Variable(data), Variable(target)\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self(data.view(data.size(0),1,28,28), path, -1)\n",
        "            pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "            correct = pred.eq(target.data).cpu().sum()\n",
        "            fitness += correct\n",
        "            train_len += len(target.data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            if not batch_idx < num_batch -1:\n",
        "                break\n",
        "        fitness = fitness / train_len\n",
        "        return fitness\n",
        "\n",
        "    def test_model(self, test_loader, path, last):\n",
        "        self.eval()\n",
        "\n",
        "        # For now we will throw out the path given to us and just run on the entire network.\n",
        "\n",
        "        fitness = float(0)\n",
        "        train_len = 0\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            if self.use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            data, target = Variable(data), Variable(target)\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self(data.view(1000,1,28,28), path, last)\n",
        "            pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "            fitness += pred.eq(target.data).cpu().sum()\n",
        "            train_len += len(target.data)\n",
        "\n",
        "        fitness = fitness / train_len\n",
        "        return fitness\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr0OQ5RWImXF",
        "colab_type": "text"
      },
      "source": [
        "# Run Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI9uv-uKBiGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_pathnet(model, gene, train_loader, num_batch, best_fitness, best_path, gen):\n",
        "    pathways = gene.sample()\n",
        "    fitnesses = []\n",
        "    train_data = [(data, target) for (data,target) in train_loader]\n",
        "    for pathway in pathways:\n",
        "        path = pathway.return_genotype()\n",
        "        fitness = model.train_model(train_data, path, num_batch)\n",
        "        fitnesses.append(fitness)\n",
        "\n",
        "    gene.overwrite(pathways, fitnesses)\n",
        "    genes = gene.return_all_genotypes()\n",
        "\n",
        "    if max(fitnesses) > best_fitness:\n",
        "        best_fitness = max(fitnesses)\n",
        "        best_path = pathways[fitnesses.index(max(fitnesses))].return_genotype()\n",
        "    \n",
        "    return best_fitness, best_path, max(fitnesses)\n",
        "\n",
        "def train_control(model, gene, train_loader, gen):        \n",
        "    path = gene.return_control_genotype()\n",
        "    train_data = [(data, target) for (data,target) in train_loader]\n",
        "    fitness = model.train_model(train_data, path, args.num_batch)\n",
        "\n",
        "    genes = [gene.return_control_genotype()] * args.pop\n",
        "    \n",
        "    return fitness\n",
        "\n",
        "def evaluate_on_tasks(model, tasks_trained, test_loaders, best_paths):\n",
        "    print(\"Evaluating on task test sets\")\n",
        "    test_acc = []\n",
        "    for k in range(n_tasks):\n",
        "        i = k if k <= tasks_trained else -1\n",
        "        fitness = model.test_model(test_loaders[k], best_paths[i], i)\n",
        "        print(\"Test Accuracy on Task Set {}: {}\".format(k, fitness))\n",
        "        test_acc.append(fitness.item())\n",
        "    print(\"Average Test Accuracy: {}\".format(np.mean(test_acc)))\n",
        "    return test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTwMhvtOweQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    # Training settings\n",
        "    L = 2\n",
        "    M = 10\n",
        "    N = 4\n",
        "    pop = 64\n",
        "    batch_size = 16\n",
        "    batch_limit = 150\n",
        "    lr = 0.01\n",
        "    num_neurons = 20\n",
        "    generation_limit = 50\n",
        "    control = False\n",
        "    fine_tune = False\n",
        "    use_cuda = True\n",
        "    seed = 0\n",
        "\n",
        "    cuda = use_cuda and torch.cuda.is_available()\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "\n",
        "    model = Net(L, M, N, num_neurons, lr, cuda)\n",
        "\n",
        "    if cuda:\n",
        "        model.cuda()\n",
        "\n",
        "    if not os.path.isdir('./result'):\n",
        "        os.makedirs(\"./result\")\n",
        "\n",
        "    if os.path.exists('./result/result_mnist.pickle'):\n",
        "        f = open('./result/result_mnist.pickle','rb')\n",
        "        result = pickle.load(f)\n",
        "        f.close()\n",
        "    else:\n",
        "        result = []\n",
        "\n",
        "    test_loaders = []\n",
        "    for i in range(n_tasks):\n",
        "        test_loaders.append(data_utils.DataLoader(data_utils.TensorDataset(tasks_te[i][1], tasks_te[i][2]), batch_size=1000, shuffle = False))\n",
        "\n",
        "    best_paths = []\n",
        "    best_path = [[None] * N] * L\n",
        "    total_test_acc = []\n",
        "    tasks_fitness = []\n",
        "    gene = Genetic(L, M, N, pop)\n",
        "\n",
        "    # Then train across tasks\n",
        "    for i in range(n_tasks):\n",
        "        gen = 0\n",
        "        best_fitness = 0.0\n",
        "        task_fitness = []\n",
        "\n",
        "        # If not control, generate a new gene which controls the permutations of pathways\n",
        "        if not control:\n",
        "          gene = Genetic(L, M, N, pop)\n",
        "\n",
        "        # Initialize (or reinitialise) our model\n",
        "        model.init(best_paths, i+1)\n",
        "        \n",
        "        # Load our training data\n",
        "        train = data_utils.TensorDataset(tasks_tr[i][1], tasks_tr[i][2])\n",
        "        train_loader = data_utils.DataLoader(train, batch_size=batch_size, shuffle = True)\n",
        "        print(\"Training Task {} started...\".format(i))\n",
        "        \n",
        "        # Begin our training tournament\n",
        "        for gen in range(generation_limit):\n",
        "            if not control:\n",
        "                best_fitness, best_path, max_fitness = train_pathnet(model, gene, train_loader, batch_limit, best_fitness, best_path, gen)\n",
        "                task_fitness.append(max_fitness)\n",
        "            else: # control experiment\n",
        "                fitness = train_control(model, gene, train_loader, gen)\n",
        "                task_fitness.append(fitness)\n",
        "\n",
        "        # Store our best fitness and path\n",
        "        tasks_fitness.append(task_fitness)\n",
        "        best_paths.append(best_path)\n",
        "        \n",
        "        # Evaluate on our test sets\n",
        "        test_acc = evaluate_on_tasks(model, i, test_loaders, best_paths)\n",
        "        total_test_acc.append(test_acc)\n",
        "\n",
        "        print(\"Task {} done.\".format(i))\n",
        "\n",
        "    average_acc = np.mean(total_test_acc[n_tasks-1])\n",
        "    print(\"Accuracy:\", average_acc)\n",
        "    print(\"Confusion matrix:\")\n",
        "    print('\\n'.join([','.join([str(item) for item in row]) for row in total_test_acc]))\n",
        "\n",
        "    # Save our results\n",
        "    if control:\n",
        "        if fine_tune:\n",
        "            result.append(('fine_tune', total_test_acc))\n",
        "        else:\n",
        "            result.append(('control', total_test_acc))\n",
        "    else:\n",
        "        result.append(('confusion_matrix', total_test_acc))\n",
        "    f = open('./result/result_mnist.pickle', 'wb')\n",
        "    pickle.dump(result, f)\n",
        "    f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN_7QFO2fNB2",
        "colab_type": "code",
        "outputId": "a94ec48f-86c1-48fd-9c79-bb8a0dc256bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Task 0 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9366999864578247\n",
            "Test Accuracy on Task Set 2: 0.9176999926567078\n",
            "Test Accuracy on Task Set 3: 0.6410999894142151\n",
            "Test Accuracy on Task Set 4: 0.5388000011444092\n",
            "Test Accuracy on Task Set 5: 0.39320001006126404\n",
            "Test Accuracy on Task Set 6: 0.30640000104904175\n",
            "Test Accuracy on Task Set 7: 0.2410999983549118\n",
            "Test Accuracy on Task Set 8: 0.20100000500679016\n",
            "Test Accuracy on Task Set 9: 0.16539999842643738\n",
            "Test Accuracy on Task Set 10: 0.1581999957561493\n",
            "Test Accuracy on Task Set 11: 0.14550000429153442\n",
            "Test Accuracy on Task Set 12: 0.1485999971628189\n",
            "Test Accuracy on Task Set 13: 0.1680999994277954\n",
            "Test Accuracy on Task Set 14: 0.21940000355243683\n",
            "Test Accuracy on Task Set 15: 0.22699999809265137\n",
            "Test Accuracy on Task Set 16: 0.30309998989105225\n",
            "Test Accuracy on Task Set 17: 0.3025999963283539\n",
            "Test Accuracy on Task Set 18: 0.33239999413490295\n",
            "Test Accuracy on Task Set 19: 0.32850000262260437\n",
            "Average Test Accuracy: 0.38271999880671503\n",
            "Task 0 done.\n",
            "Training Task 1 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9749000072479248\n",
            "Test Accuracy on Task Set 3: 0.8884999752044678\n",
            "Test Accuracy on Task Set 4: 0.8312000036239624\n",
            "Test Accuracy on Task Set 5: 0.6916999816894531\n",
            "Test Accuracy on Task Set 6: 0.5626000165939331\n",
            "Test Accuracy on Task Set 7: 0.40689998865127563\n",
            "Test Accuracy on Task Set 8: 0.298799991607666\n",
            "Test Accuracy on Task Set 9: 0.2053000032901764\n",
            "Test Accuracy on Task Set 10: 0.20669999718666077\n",
            "Test Accuracy on Task Set 11: 0.1665000021457672\n",
            "Test Accuracy on Task Set 12: 0.15399999916553497\n",
            "Test Accuracy on Task Set 13: 0.131400004029274\n",
            "Test Accuracy on Task Set 14: 0.1289999932050705\n",
            "Test Accuracy on Task Set 15: 0.13279999792575836\n",
            "Test Accuracy on Task Set 16: 0.1808999925851822\n",
            "Test Accuracy on Task Set 17: 0.18979999423027039\n",
            "Test Accuracy on Task Set 18: 0.24420000612735748\n",
            "Test Accuracy on Task Set 19: 0.2721000015735626\n",
            "Average Test Accuracy: 0.43125999718904495\n",
            "Task 1 done.\n",
            "Training Task 2 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.8810999989509583\n",
            "Test Accuracy on Task Set 4: 0.8205000162124634\n",
            "Test Accuracy on Task Set 5: 0.677299976348877\n",
            "Test Accuracy on Task Set 6: 0.5235000252723694\n",
            "Test Accuracy on Task Set 7: 0.3564000129699707\n",
            "Test Accuracy on Task Set 8: 0.23080000281333923\n",
            "Test Accuracy on Task Set 9: 0.13899999856948853\n",
            "Test Accuracy on Task Set 10: 0.13809999823570251\n",
            "Test Accuracy on Task Set 11: 0.11299999803304672\n",
            "Test Accuracy on Task Set 12: 0.11060000211000443\n",
            "Test Accuracy on Task Set 13: 0.12479999661445618\n",
            "Test Accuracy on Task Set 14: 0.13660000264644623\n",
            "Test Accuracy on Task Set 15: 0.14090000092983246\n",
            "Test Accuracy on Task Set 16: 0.1850000023841858\n",
            "Test Accuracy on Task Set 17: 0.1881999969482422\n",
            "Test Accuracy on Task Set 18: 0.25220000743865967\n",
            "Test Accuracy on Task Set 19: 0.28999999165534973\n",
            "Average Test Accuracy: 0.41175500154495237\n",
            "Task 2 done.\n",
            "Training Task 3 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9746999740600586\n",
            "Test Accuracy on Task Set 5: 0.9534000158309937\n",
            "Test Accuracy on Task Set 6: 0.9089999794960022\n",
            "Test Accuracy on Task Set 7: 0.7832000255584717\n",
            "Test Accuracy on Task Set 8: 0.5954999923706055\n",
            "Test Accuracy on Task Set 9: 0.29989999532699585\n",
            "Test Accuracy on Task Set 10: 0.2761000096797943\n",
            "Test Accuracy on Task Set 11: 0.1704999953508377\n",
            "Test Accuracy on Task Set 12: 0.1476999968290329\n",
            "Test Accuracy on Task Set 13: 0.1347000002861023\n",
            "Test Accuracy on Task Set 14: 0.13519999384880066\n",
            "Test Accuracy on Task Set 15: 0.1395999938249588\n",
            "Test Accuracy on Task Set 16: 0.1454000025987625\n",
            "Test Accuracy on Task Set 17: 0.147599995136261\n",
            "Test Accuracy on Task Set 18: 0.17080000042915344\n",
            "Test Accuracy on Task Set 19: 0.20589999854564667\n",
            "Average Test Accuracy: 0.5047249995172024\n",
            "Task 3 done.\n",
            "Training Task 4 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9685999751091003\n",
            "Test Accuracy on Task Set 6: 0.944100022315979\n",
            "Test Accuracy on Task Set 7: 0.8597000241279602\n",
            "Test Accuracy on Task Set 8: 0.6960999965667725\n",
            "Test Accuracy on Task Set 9: 0.3898000121116638\n",
            "Test Accuracy on Task Set 10: 0.35519999265670776\n",
            "Test Accuracy on Task Set 11: 0.2280000001192093\n",
            "Test Accuracy on Task Set 12: 0.2053000032901764\n",
            "Test Accuracy on Task Set 13: 0.16130000352859497\n",
            "Test Accuracy on Task Set 14: 0.13729999959468842\n",
            "Test Accuracy on Task Set 15: 0.13940000534057617\n",
            "Test Accuracy on Task Set 16: 0.12219999730587006\n",
            "Test Accuracy on Task Set 17: 0.12060000002384186\n",
            "Test Accuracy on Task Set 18: 0.13439999520778656\n",
            "Test Accuracy on Task Set 19: 0.1589999943971634\n",
            "Average Test Accuracy: 0.5251500025391579\n",
            "Task 4 done.\n",
            "Training Task 5 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.968999981880188\n",
            "Test Accuracy on Task Set 7: 0.9384999871253967\n",
            "Test Accuracy on Task Set 8: 0.8551999926567078\n",
            "Test Accuracy on Task Set 9: 0.5692999958992004\n",
            "Test Accuracy on Task Set 10: 0.5239999890327454\n",
            "Test Accuracy on Task Set 11: 0.3095000088214874\n",
            "Test Accuracy on Task Set 12: 0.26759999990463257\n",
            "Test Accuracy on Task Set 13: 0.1695999950170517\n",
            "Test Accuracy on Task Set 14: 0.14499999582767487\n",
            "Test Accuracy on Task Set 15: 0.147599995136261\n",
            "Test Accuracy on Task Set 16: 0.1518000066280365\n",
            "Test Accuracy on Task Set 17: 0.1509999930858612\n",
            "Test Accuracy on Task Set 18: 0.16539999842643738\n",
            "Test Accuracy on Task Set 19: 0.1860000044107437\n",
            "Average Test Accuracy: 0.5704249985516071\n",
            "Task 5 done.\n",
            "Training Task 6 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9702000021934509\n",
            "Test Accuracy on Task Set 8: 0.9257000088691711\n",
            "Test Accuracy on Task Set 9: 0.7032999992370605\n",
            "Test Accuracy on Task Set 10: 0.6615999937057495\n",
            "Test Accuracy on Task Set 11: 0.4124000072479248\n",
            "Test Accuracy on Task Set 12: 0.35589998960494995\n",
            "Test Accuracy on Task Set 13: 0.21279999613761902\n",
            "Test Accuracy on Task Set 14: 0.16220000386238098\n",
            "Test Accuracy on Task Set 15: 0.15809999406337738\n",
            "Test Accuracy on Task Set 16: 0.14820000529289246\n",
            "Test Accuracy on Task Set 17: 0.14470000565052032\n",
            "Test Accuracy on Task Set 18: 0.14509999752044678\n",
            "Test Accuracy on Task Set 19: 0.15449999272823334\n",
            "Average Test Accuracy: 0.5996600009500981\n",
            "Task 6 done.\n",
            "Training Task 7 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9628000259399414\n",
            "Test Accuracy on Task Set 9: 0.8496000170707703\n",
            "Test Accuracy on Task Set 10: 0.8165000081062317\n",
            "Test Accuracy on Task Set 11: 0.5728999972343445\n",
            "Test Accuracy on Task Set 12: 0.5097000002861023\n",
            "Test Accuracy on Task Set 13: 0.28119999170303345\n",
            "Test Accuracy on Task Set 14: 0.17499999701976776\n",
            "Test Accuracy on Task Set 15: 0.1673000007867813\n",
            "Test Accuracy on Task Set 16: 0.13920000195503235\n",
            "Test Accuracy on Task Set 17: 0.13689999282360077\n",
            "Test Accuracy on Task Set 18: 0.13979999721050262\n",
            "Test Accuracy on Task Set 19: 0.1467999964952469\n",
            "Average Test Accuracy: 0.6356450028717517\n",
            "Task 7 done.\n",
            "Training Task 8 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9386000037193298\n",
            "Test Accuracy on Task Set 10: 0.9190000295639038\n",
            "Test Accuracy on Task Set 11: 0.7748000025749207\n",
            "Test Accuracy on Task Set 12: 0.6984999775886536\n",
            "Test Accuracy on Task Set 13: 0.4239000082015991\n",
            "Test Accuracy on Task Set 14: 0.2556000053882599\n",
            "Test Accuracy on Task Set 15: 0.24379999935626984\n",
            "Test Accuracy on Task Set 16: 0.15680000185966492\n",
            "Test Accuracy on Task Set 17: 0.15219999849796295\n",
            "Test Accuracy on Task Set 18: 0.14010000228881836\n",
            "Test Accuracy on Task Set 19: 0.1362999975681305\n",
            "Average Test Accuracy: 0.6815350025892257\n",
            "Task 8 done.\n",
            "Training Task 9 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9695000052452087\n",
            "Test Accuracy on Task Set 11: 0.9261000156402588\n",
            "Test Accuracy on Task Set 12: 0.8956000208854675\n",
            "Test Accuracy on Task Set 13: 0.6730999946594238\n",
            "Test Accuracy on Task Set 14: 0.42289999127388\n",
            "Test Accuracy on Task Set 15: 0.38960000872612\n",
            "Test Accuracy on Task Set 16: 0.19249999523162842\n",
            "Test Accuracy on Task Set 17: 0.1809999942779541\n",
            "Test Accuracy on Task Set 18: 0.14329999685287476\n",
            "Test Accuracy on Task Set 19: 0.1378999948501587\n",
            "Average Test Accuracy: 0.7349250018596649\n",
            "Task 9 done.\n",
            "Training Task 10 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9492999911308289\n",
            "Test Accuracy on Task Set 12: 0.9359999895095825\n",
            "Test Accuracy on Task Set 13: 0.8077999949455261\n",
            "Test Accuracy on Task Set 14: 0.5839999914169312\n",
            "Test Accuracy on Task Set 15: 0.5504000186920166\n",
            "Test Accuracy on Task Set 16: 0.2709999978542328\n",
            "Test Accuracy on Task Set 17: 0.23849999904632568\n",
            "Test Accuracy on Task Set 18: 0.16850000619888306\n",
            "Test Accuracy on Task Set 19: 0.14339999854564667\n",
            "Average Test Accuracy: 0.7691600002348423\n",
            "Task 10 done.\n",
            "Training Task 11 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9782000184059143\n",
            "Test Accuracy on Task Set 12: 0.9732999801635742\n",
            "Test Accuracy on Task Set 13: 0.9304999709129333\n",
            "Test Accuracy on Task Set 14: 0.7803000211715698\n",
            "Test Accuracy on Task Set 15: 0.7455000281333923\n",
            "Test Accuracy on Task Set 16: 0.43130001425743103\n",
            "Test Accuracy on Task Set 17: 0.37450000643730164\n",
            "Test Accuracy on Task Set 18: 0.23680000007152557\n",
            "Test Accuracy on Task Set 19: 0.15600000321865082\n",
            "Average Test Accuracy: 0.8170350030064583\n",
            "Task 11 done.\n",
            "Training Task 12 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9782000184059143\n",
            "Test Accuracy on Task Set 12: 0.9718000292778015\n",
            "Test Accuracy on Task Set 13: 0.9557999968528748\n",
            "Test Accuracy on Task Set 14: 0.8568999767303467\n",
            "Test Accuracy on Task Set 15: 0.8353999853134155\n",
            "Test Accuracy on Task Set 16: 0.5206999778747559\n",
            "Test Accuracy on Task Set 17: 0.46309998631477356\n",
            "Test Accuracy on Task Set 18: 0.2793999910354614\n",
            "Test Accuracy on Task Set 19: 0.16680000722408295\n",
            "Average Test Accuracy: 0.8381199993193149\n",
            "Task 12 done.\n",
            "Training Task 13 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9782000184059143\n",
            "Test Accuracy on Task Set 12: 0.9718000292778015\n",
            "Test Accuracy on Task Set 13: 0.9726999998092651\n",
            "Test Accuracy on Task Set 14: 0.9449999928474426\n",
            "Test Accuracy on Task Set 15: 0.9343000054359436\n",
            "Test Accuracy on Task Set 16: 0.7516999840736389\n",
            "Test Accuracy on Task Set 17: 0.7074999809265137\n",
            "Test Accuracy on Task Set 18: 0.5058000087738037\n",
            "Test Accuracy on Task Set 19: 0.2946999967098236\n",
            "Average Test Accuracy: 0.8898000016808509\n",
            "Task 13 done.\n",
            "Training Task 14 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9782000184059143\n",
            "Test Accuracy on Task Set 12: 0.9718000292778015\n",
            "Test Accuracy on Task Set 13: 0.9726999998092651\n",
            "Test Accuracy on Task Set 14: 0.9739000201225281\n",
            "Test Accuracy on Task Set 15: 0.9711999893188477\n",
            "Test Accuracy on Task Set 16: 0.9151999950408936\n",
            "Test Accuracy on Task Set 17: 0.8891000151634216\n",
            "Test Accuracy on Task Set 18: 0.7376000285148621\n",
            "Test Accuracy on Task Set 19: 0.4887000024318695\n",
            "Average Test Accuracy: 0.9316350057721138\n",
            "Task 14 done.\n",
            "Training Task 15 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9782000184059143\n",
            "Test Accuracy on Task Set 12: 0.9718000292778015\n",
            "Test Accuracy on Task Set 13: 0.9726999998092651\n",
            "Test Accuracy on Task Set 14: 0.9739000201225281\n",
            "Test Accuracy on Task Set 15: 0.9740999937057495\n",
            "Test Accuracy on Task Set 16: 0.8991000056266785\n",
            "Test Accuracy on Task Set 17: 0.8708999752998352\n",
            "Test Accuracy on Task Set 18: 0.7161999940872192\n",
            "Test Accuracy on Task Set 19: 0.48730000853538513\n",
            "Average Test Accuracy: 0.9289250031113625\n",
            "Task 15 done.\n",
            "Training Task 16 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9782000184059143\n",
            "Test Accuracy on Task Set 12: 0.9718000292778015\n",
            "Test Accuracy on Task Set 13: 0.9726999998092651\n",
            "Test Accuracy on Task Set 14: 0.9739000201225281\n",
            "Test Accuracy on Task Set 15: 0.9740999937057495\n",
            "Test Accuracy on Task Set 16: 0.9693999886512756\n",
            "Test Accuracy on Task Set 17: 0.9699000120162964\n",
            "Test Accuracy on Task Set 18: 0.949999988079071\n",
            "Test Accuracy on Task Set 19: 0.8580999970436096\n",
            "Average Test Accuracy: 0.9676200032234192\n",
            "Task 16 done.\n",
            "Training Task 17 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9782000184059143\n",
            "Test Accuracy on Task Set 12: 0.9718000292778015\n",
            "Test Accuracy on Task Set 13: 0.9726999998092651\n",
            "Test Accuracy on Task Set 14: 0.9739000201225281\n",
            "Test Accuracy on Task Set 15: 0.9740999937057495\n",
            "Test Accuracy on Task Set 16: 0.9693999886512756\n",
            "Test Accuracy on Task Set 17: 0.9750999808311462\n",
            "Test Accuracy on Task Set 18: 0.9595000147819519\n",
            "Test Accuracy on Task Set 19: 0.8677999973297119\n",
            "Average Test Accuracy: 0.9688400030136108\n",
            "Task 17 done.\n",
            "Training Task 18 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9782000184059143\n",
            "Test Accuracy on Task Set 12: 0.9718000292778015\n",
            "Test Accuracy on Task Set 13: 0.9726999998092651\n",
            "Test Accuracy on Task Set 14: 0.9739000201225281\n",
            "Test Accuracy on Task Set 15: 0.9740999937057495\n",
            "Test Accuracy on Task Set 16: 0.9693999886512756\n",
            "Test Accuracy on Task Set 17: 0.9750999808311462\n",
            "Test Accuracy on Task Set 18: 0.9725000262260437\n",
            "Test Accuracy on Task Set 19: 0.9484000205993652\n",
            "Average Test Accuracy: 0.9735200047492981\n",
            "Task 18 done.\n",
            "Training Task 19 started...\n",
            "Evaluating on task test sets\n",
            "Test Accuracy on Task Set 0: 0.9796000123023987\n",
            "Test Accuracy on Task Set 1: 0.9782999753952026\n",
            "Test Accuracy on Task Set 2: 0.9692000150680542\n",
            "Test Accuracy on Task Set 3: 0.9782000184059143\n",
            "Test Accuracy on Task Set 4: 0.9767000079154968\n",
            "Test Accuracy on Task Set 5: 0.9769999980926514\n",
            "Test Accuracy on Task Set 6: 0.9794999957084656\n",
            "Test Accuracy on Task Set 7: 0.9767000079154968\n",
            "Test Accuracy on Task Set 8: 0.9758999943733215\n",
            "Test Accuracy on Task Set 9: 0.9758999943733215\n",
            "Test Accuracy on Task Set 10: 0.9672999978065491\n",
            "Test Accuracy on Task Set 11: 0.9782000184059143\n",
            "Test Accuracy on Task Set 12: 0.9718000292778015\n",
            "Test Accuracy on Task Set 13: 0.9726999998092651\n",
            "Test Accuracy on Task Set 14: 0.9739000201225281\n",
            "Test Accuracy on Task Set 15: 0.9740999937057495\n",
            "Test Accuracy on Task Set 16: 0.9693999886512756\n",
            "Test Accuracy on Task Set 17: 0.9750999808311462\n",
            "Test Accuracy on Task Set 18: 0.9725000262260437\n",
            "Test Accuracy on Task Set 19: 0.9715999960899353\n",
            "Average Test Accuracy: 0.9746800035238266\n",
            "Task 19 done.\n",
            "Accuracy: 0.9746800035238266\n",
            "Confusion matrix:\n",
            "0.9796000123023987,0.9366999864578247,0.9176999926567078,0.6410999894142151,0.5388000011444092,0.39320001006126404,0.30640000104904175,0.2410999983549118,0.20100000500679016,0.16539999842643738,0.1581999957561493,0.14550000429153442,0.1485999971628189,0.1680999994277954,0.21940000355243683,0.22699999809265137,0.30309998989105225,0.3025999963283539,0.33239999413490295,0.32850000262260437\n",
            "0.9796000123023987,0.9782999753952026,0.9749000072479248,0.8884999752044678,0.8312000036239624,0.6916999816894531,0.5626000165939331,0.40689998865127563,0.298799991607666,0.2053000032901764,0.20669999718666077,0.1665000021457672,0.15399999916553497,0.131400004029274,0.1289999932050705,0.13279999792575836,0.1808999925851822,0.18979999423027039,0.24420000612735748,0.2721000015735626\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.8810999989509583,0.8205000162124634,0.677299976348877,0.5235000252723694,0.3564000129699707,0.23080000281333923,0.13899999856948853,0.13809999823570251,0.11299999803304672,0.11060000211000443,0.12479999661445618,0.13660000264644623,0.14090000092983246,0.1850000023841858,0.1881999969482422,0.25220000743865967,0.28999999165534973\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9746999740600586,0.9534000158309937,0.9089999794960022,0.7832000255584717,0.5954999923706055,0.29989999532699585,0.2761000096797943,0.1704999953508377,0.1476999968290329,0.1347000002861023,0.13519999384880066,0.1395999938249588,0.1454000025987625,0.147599995136261,0.17080000042915344,0.20589999854564667\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9685999751091003,0.944100022315979,0.8597000241279602,0.6960999965667725,0.3898000121116638,0.35519999265670776,0.2280000001192093,0.2053000032901764,0.16130000352859497,0.13729999959468842,0.13940000534057617,0.12219999730587006,0.12060000002384186,0.13439999520778656,0.1589999943971634\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.968999981880188,0.9384999871253967,0.8551999926567078,0.5692999958992004,0.5239999890327454,0.3095000088214874,0.26759999990463257,0.1695999950170517,0.14499999582767487,0.147599995136261,0.1518000066280365,0.1509999930858612,0.16539999842643738,0.1860000044107437\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9702000021934509,0.9257000088691711,0.7032999992370605,0.6615999937057495,0.4124000072479248,0.35589998960494995,0.21279999613761902,0.16220000386238098,0.15809999406337738,0.14820000529289246,0.14470000565052032,0.14509999752044678,0.15449999272823334\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9628000259399414,0.8496000170707703,0.8165000081062317,0.5728999972343445,0.5097000002861023,0.28119999170303345,0.17499999701976776,0.1673000007867813,0.13920000195503235,0.13689999282360077,0.13979999721050262,0.1467999964952469\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9386000037193298,0.9190000295639038,0.7748000025749207,0.6984999775886536,0.4239000082015991,0.2556000053882599,0.24379999935626984,0.15680000185966492,0.15219999849796295,0.14010000228881836,0.1362999975681305\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9695000052452087,0.9261000156402588,0.8956000208854675,0.6730999946594238,0.42289999127388,0.38960000872612,0.19249999523162842,0.1809999942779541,0.14329999685287476,0.1378999948501587\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9492999911308289,0.9359999895095825,0.8077999949455261,0.5839999914169312,0.5504000186920166,0.2709999978542328,0.23849999904632568,0.16850000619888306,0.14339999854564667\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9782000184059143,0.9732999801635742,0.9304999709129333,0.7803000211715698,0.7455000281333923,0.43130001425743103,0.37450000643730164,0.23680000007152557,0.15600000321865082\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9782000184059143,0.9718000292778015,0.9557999968528748,0.8568999767303467,0.8353999853134155,0.5206999778747559,0.46309998631477356,0.2793999910354614,0.16680000722408295\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9782000184059143,0.9718000292778015,0.9726999998092651,0.9449999928474426,0.9343000054359436,0.7516999840736389,0.7074999809265137,0.5058000087738037,0.2946999967098236\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9782000184059143,0.9718000292778015,0.9726999998092651,0.9739000201225281,0.9711999893188477,0.9151999950408936,0.8891000151634216,0.7376000285148621,0.4887000024318695\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9782000184059143,0.9718000292778015,0.9726999998092651,0.9739000201225281,0.9740999937057495,0.8991000056266785,0.8708999752998352,0.7161999940872192,0.48730000853538513\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9782000184059143,0.9718000292778015,0.9726999998092651,0.9739000201225281,0.9740999937057495,0.9693999886512756,0.9699000120162964,0.949999988079071,0.8580999970436096\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9782000184059143,0.9718000292778015,0.9726999998092651,0.9739000201225281,0.9740999937057495,0.9693999886512756,0.9750999808311462,0.9595000147819519,0.8677999973297119\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9782000184059143,0.9718000292778015,0.9726999998092651,0.9739000201225281,0.9740999937057495,0.9693999886512756,0.9750999808311462,0.9725000262260437,0.9484000205993652\n",
            "0.9796000123023987,0.9782999753952026,0.9692000150680542,0.9782000184059143,0.9767000079154968,0.9769999980926514,0.9794999957084656,0.9767000079154968,0.9758999943733215,0.9758999943733215,0.9672999978065491,0.9782000184059143,0.9718000292778015,0.9726999998092651,0.9739000201225281,0.9740999937057495,0.9693999886512756,0.9750999808311462,0.9725000262260437,0.9715999960899353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnM9oAWHqJcT",
        "colab_type": "text"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCnGbHT1wbVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
        "parser.add_argument('--mnist', action='store_true', default=True,\n",
        "                    help='open mnist result')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "\n",
        "def subplot(subplot, data_first, data_second, data_third, data_first_control, data_second_control, data_third_control, title):\n",
        "    plt.subplot(subplot)\n",
        "    if args.mnist:\n",
        "        x = np.arange(0,100)\n",
        "    else:\n",
        "        x = np.arange(0,500)\n",
        "    y_first = np.mean(data_first, axis=0)\n",
        "    y_second = np.mean(data_second, axis=0)\n",
        "    y_third = np.mean(data_third, axis=0)\n",
        "    y_first_control = np.mean(data_first_control, axis=0)\n",
        "    y_second_control = np.mean(data_second_control, axis=0)\n",
        "    y_third_control = np.mean(data_third_control, axis=0)\n",
        "    #y_first_err = np.std(data_first, axis=0) / 2.\n",
        "    #y_second_err = np.std(data_second, axis=0) / 2. \n",
        "    #y_third_err = np.std(data_third, axis=0) / 2. \n",
        "    \n",
        "    #plt.fill_between(x, y_first - y_first_err, y_first + y_first_err, color='m', alpha=0.3)\n",
        "    #plt.fill_between(x, y_second - y_second_err, y_second + y_second_err, color='y', alpha=0.3)\n",
        "    #plt.fill_between(x, y_third - y_third_err, y_third + y_third_err, color='c', alpha=0.3)\n",
        "    plt.plot(x, y_first, color='r', label='Task A')\n",
        "    plt.plot(x, y_second, color='g', label='Task B')\n",
        "    plt.plot(x, y_third, color='b', label='Task C')\n",
        "    plt.plot(x, y_first_control, linestyle='dashed', color='r', label='Task A (control')\n",
        "    plt.plot(x, y_second_control, linestyle='dashed', color='g', label='Task B (control)')\n",
        "    plt.plot(x, y_third_control, linestyle='dashed', color='b', label='Task C (control)')\n",
        "    plt.legend(bbox_to_anchor=(0.8, 0.3), loc=2, ncol=1, fontsize=15)\n",
        "    axes = plt.gca()\n",
        "\n",
        "    if args.mnist:\n",
        "        axes.set_xlim([0, 100])\n",
        "        axes.set_ylim([0, 1.2])\n",
        "    else:\n",
        "        axes.set_xlim([0, 500])\n",
        "        axes.set_ylim([0, 0.6])\n",
        "    plt.title(title, fontsize=20, y = 0.9)\n",
        "    plt.ylabel('Accuracy',fontsize=15)\n",
        "    plt.xlabel('Generations',fontsize=15)\n",
        "    plt.grid(True)\n",
        "\n",
        "\n",
        "try: \n",
        "    if args.mnist:\n",
        "        f = open(os.path.join('./result/result_mnist.pickle'), 'rb')\n",
        "        result = pickle.load(f)\n",
        "        f.close()\n",
        "        pathnet_first = [result[1][2]]\n",
        "        pathnet_second = [result[1][3]]\n",
        "        pathnet_third = [result[1][4]]\n",
        "\n",
        "        pathnet_first_control = [result[0][2]]\n",
        "        pathnet_second_control = [result[0][3]]\n",
        "        pathnet_third_control = [result[0][4]]\n",
        "\n",
        "        #for res in result:\n",
        "            #pathnet_first.append(res[2])\n",
        "            #pathnet_second.append(res[3])\n",
        "            #pathnet_third.append(res[4])\n",
        "\n",
        "        subplot('111', pathnet_first, pathnet_second, pathnet_third, pathnet_first_control, pathnet_second_control, pathnet_third_control, 'MNIST')\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        f = open(os.path.join('./result/result_cifar_svhn.pickle'))\n",
        "        result = pickle.load(f)\n",
        "        f.close()\n",
        "\n",
        "        cifar_first = []\n",
        "        cifar_second = []\n",
        "        svhn_first = []\n",
        "        svhn_second = []\n",
        "\n",
        "        for res in result:\n",
        "            if res[0] == 'pathnet_cifar_first':\n",
        "                cifar_first.append(res[2])\n",
        "                svhn_second.append(res[3])\n",
        "            else:\n",
        "                svhn_first.append(res[2])\n",
        "                cifar_second.append(res[3])\n",
        "\n",
        "        subplot('211', cifar_first, cifar_second,'CIFAR-10')\n",
        "        subplot('212', svhn_first, svhn_second,'cSVHN')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "except IOError:\n",
        "    print(\"Result file does not exist\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}